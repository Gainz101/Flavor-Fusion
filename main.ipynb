{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yezenhijazin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yezenhijazin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import google.generativeai as palm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Import dataset\n",
    "df = pd.read_csv('all_recipies.csv')\n",
    "\n",
    "# Create lists of types and descriptions\n",
    "food_types = df['recipe_name'].tolist()\n",
    "food_decr_raw = df['description'].tolist()\n",
    "\n",
    "# Download the stopwords from NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to process each description\n",
    "def preprocess(description):\n",
    "    tokens = word_tokenize(description)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    postprocessed_desc = [w.lower() for w in tokens if not w.lower() in stop_words]\n",
    "    return \" \".join(postprocessed_desc)\n",
    "\n",
    "# Preprocess all food descriptions\n",
    "food_decr = [preprocess(desc) for desc in food_decr_raw]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=[word_tokenize(desc) for desc in food_decr], vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Word2Vec embeddings to initialize Doc2Vec model\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(food_decr)]\n",
    "doc2vec_model = Doc2Vec(vector_size=50, window=5, min_count=1, workers=4, epochs=100)\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.wv = word2vec_model.wv  # Use Word2Vec embeddings\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar food item to the combined dining history is: Thai Seafood Coconut Curry Soup\n"
     ]
    }
   ],
   "source": [
    "dining_history=[]\n",
    "dining_histories=[]\n",
    "users=input(\"How many people are in your party? \")\n",
    "for i in range(int(users)):\n",
    "    for j in range(0,5):\n",
    "        dining_history.append(input(\"Enter 5 food you've ate recentely or that you like for user \"+str(i+1)+\": \"))\n",
    "    dining_histories.append(dining_history)\n",
    "    dining_history=[]\n",
    "\n",
    "# Create a list of dining histories for multiple users\n",
    "# dining_histories = [[\"lasanga\", \"pesto pasta\", \"pizza\",\"gnocchi\",\"calzone\"],[\"sushi\",\"sashimi\",\"ramen\",\"udon\",\"fish\"]]\n",
    "\n",
    "# Combine all dining histories into one\n",
    "combined_dining_history = [item for sublist in dining_histories for item in sublist]\n",
    "\n",
    "# Get the document vector for the combined dining history\n",
    "combined_vector = doc2vec_model.infer_vector(word_tokenize(\" \".join(combined_dining_history).lower()))\n",
    "\n",
    "# Find the most similar food item from the dataset\n",
    "similar_documents = doc2vec_model.dv.most_similar([combined_vector], topn=1)\n",
    "similar_food_index = int(similar_documents[0][0])\n",
    "similar_food = food_types[similar_food_index]\n",
    "\n",
    "# Calculate cosine similarity between the combined vector and all food vectors\n",
    "# similarities = [cosine_similarity([combined_vector], [doc2vec_model.dv[i]])[0][0] for i in range(len(food_types))]\n",
    "\n",
    "# # Find the index of the most similar food item\n",
    "# similar_food_index = similarities.index(max(similarities))\n",
    "# similar_food = food_types[similar_food_index]\n",
    "\n",
    "# Print the most similar food item\n",
    "print(f\"The most similar food item to the combined dining history of all users is: {similar_food}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Genre:** Southern\n",
      "\n",
      "**Restaurants in College Station, TX:**\n",
      "\n",
      "* **The Refuge** is a popular spot for Southern comfort food, and their watermelon salad is one of the most popular dishes on the menu. The salad is made with fresh watermelon, feta cheese, mint, and a balsamic vinaigrette.\n",
      "* **The Junction** is another great option for Southern food. Their watermelon salad is made with watermelon, candied pecans, goat cheese, and a honey-lime dressing.\n",
      "* **The Backyard** is a casual, outdoor restaurant that serves up some of the best Southern food in town. Their watermelon salad is made with watermelon, strawberries, goat cheese, and a balsamic vinaigrette.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "palm.configure(api_key= \"AIzaSyCMo4_bDMpu-GArtcs5T5S4rrlfMshnSwg\")\n",
    "\n",
    "models = [\n",
    "    m for m in palm.list_models() if \"generateText\" in m.supported_generation_methods\n",
    "]\n",
    "\n",
    "model = models[0].name\n",
    "\n",
    "prompt = \"Given the food item \"+similar_food+\" suggest a broad genre or type of cuisine that matches this preference. Additionally, provide recommendations for restaurants in College Station, TX within this genre.\" \n",
    "\n",
    "\n",
    "completion = palm.generate_text(\n",
    "    model = model,\n",
    "    prompt=prompt,\n",
    "    temperature=0.33,\n",
    "    # max length of the response\n",
    "    max_output_tokens=800,\n",
    "    \n",
    ")\n",
    "\n",
    "print(completion.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
